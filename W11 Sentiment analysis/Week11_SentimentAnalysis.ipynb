{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:29:23.123680Z",
     "start_time": "2020-08-08T18:29:23.119604Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using NLTK Sentiment Intensity Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:29:25.026229Z",
     "start_time": "2020-08-08T18:29:25.018933Z"
    }
   },
   "outputs": [],
   "source": [
    "hotel_review = [\"Great resort to stay in when you visit the Dominican Republic.\",\n",
    "                \"Rooms were under renovation when I visited, so the availability was limited.\",\n",
    "                \"Love the ocean breeze and the food.\",\n",
    "                \"The food is delicious but not over the top.\",\n",
    "                \"Service - Little slow, probably because of too many people.\",\n",
    "                \"The place is not easy to find.\",\n",
    "                \"Prawns cooked in local specialty sauce were tasty.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:29:34.087473Z",
     "start_time": "2020-08-08T18:29:34.056623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great resort to stay in when you visit the Dominican Republic.\n",
      "neg: 0.0, neu: 0.709, pos: 0.291, compound: 0.6249, \n",
      "Rooms were under renovation when I visited, so the availability was limited.\n",
      "neg: 0.16, neu: 0.84, pos: 0.0, compound: -0.2263, \n",
      "Love the ocean breeze and the food.\n",
      "neg: 0.0, neu: 0.588, pos: 0.412, compound: 0.6369, \n",
      "The food is delicious but not over the top.\n",
      "neg: 0.168, neu: 0.623, pos: 0.209, compound: 0.1184, \n",
      "Service - Little slow, probably because of too many people.\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n",
      "The place is not easy to find.\n",
      "neg: 0.286, neu: 0.714, pos: 0.0, compound: -0.3412, \n",
      "Prawns cooked in local specialty sauce were tasty.\n",
      "neg: 0.0, neu: 1.0, pos: 0.0, compound: 0.0, \n"
     ]
    }
   ],
   "source": [
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in hotel_review:\n",
    "    print(sentence)\n",
    "    scores = sent_analyzer.polarity_scores(sentence)\n",
    "    for k in scores:\n",
    "        print('{0}: {1}, '.format(k, scores[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:44:40.216778Z",
     "start_time": "2020-08-08T18:44:40.211493Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(score, alpha=15):\n",
    "    \"\"\"\n",
    "    Normalize the score to be between -1 and 1 using an alpha that\n",
    "    approximates the max expected value\n",
    "    \"\"\"\n",
    "    norm_score = score/math.sqrt((score*score) + alpha)\n",
    "    return norm_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Naive Bayes Classifier (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:31:10.029412Z",
     "start_time": "2020-08-08T20:31:09.939675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "training_set = [(\"Great resort to stay in when you visit the Dominican Republic.\",\"pos\"),\n",
    "                (\"Rooms were under renovation when I visited, so the availability was limited.\",\"neg\"),\n",
    "                (\"Love the ocean breeze and the food.\",\"pos\"),\n",
    "                (\"The food is delicious but not over the top.\",\"neg\"),\n",
    "                (\"Service - Little slow, probably because of too many people.\",\"neg\"),\n",
    "                (\"The place is not easy to find.\",\"neg\"),\n",
    "                (\"V interesting!\",\"pos\"),\n",
    "                (\"V much interesting!\",\"neg\"),\n",
    "                (\"Does that add value?!\",\"neg\"),\n",
    "                (\"Prawns cooked in a local specialty sauce were tasty.\", \"pos\")]\n",
    "\n",
    "  \n",
    "# Step 2 \n",
    "dictionary = set(word.lower() for passage in training_set for word in word_tokenize(passage[0]))\n",
    "  \n",
    "# Step 3\n",
    "t = [({word: (word in word_tokenize(x[0])) for word in dictionary}, x[1]) for x in training_set]\n",
    "  \n",
    "# Step 4 â€“ the classifier is trained with sample data\n",
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "  \n",
    "test_data = \"Service - Little slow, probably because of too many people\"\n",
    "test_data_features = {word.lower(): (word in word_tokenize(test_data.lower())) for word in dictionary}\n",
    "  \n",
    "print (classifier.classify(test_data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T20:31:12.262234Z",
     "start_time": "2020-08-08T20:31:12.246423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "test_data = \"Just way V interesting.\"\n",
    "test_data_features = {word.lower(): (word in word_tokenize(test_data.lower())) for word in dictionary}\n",
    "  \n",
    "print (classifier.classify(test_data_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjectivity analysis using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:44:58.875290Z",
     "start_time": "2020-08-08T18:44:58.865595Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain a set of 100 subjective and 100 objective sentences from NLTK subjectivity corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:01.419393Z",
     "start_time": "2020-08-08T18:45:01.390871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_instances = 100\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "len(subj_docs), len(obj_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:02.788470Z",
     "start_time": "2020-08-08T18:45:02.781435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['emerging',\n",
       "  'from',\n",
       "  'the',\n",
       "  'human',\n",
       "  'psyche',\n",
       "  'and',\n",
       "  'showing',\n",
       "  'characteristics',\n",
       "  'of',\n",
       "  'abstract',\n",
       "  'expressionism',\n",
       "  ',',\n",
       "  'minimalism',\n",
       "  'and',\n",
       "  'russian',\n",
       "  'constructivism',\n",
       "  ',',\n",
       "  'graffiti',\n",
       "  'removal',\n",
       "  'has',\n",
       "  'secured',\n",
       "  'its',\n",
       "  'place',\n",
       "  'in',\n",
       "  'the',\n",
       "  'history',\n",
       "  'of',\n",
       "  'modern',\n",
       "  'art',\n",
       "  'while',\n",
       "  'being',\n",
       "  'created',\n",
       "  'by',\n",
       "  'artists',\n",
       "  'who',\n",
       "  'are',\n",
       "  'unconscious',\n",
       "  'of',\n",
       "  'their',\n",
       "  'artistic',\n",
       "  'achievements',\n",
       "  '.'],\n",
       " 'obj')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_docs[1] # each input consist of sentence represented as a list of strings, and a label (subj or obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:03.997281Z",
     "start_time": "2020-08-08T18:45:03.991771Z"
    }
   },
   "outputs": [],
   "source": [
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:100]\n",
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:100]\n",
    "training_docs = train_subj_docs+train_obj_docs\n",
    "testing_docs = test_subj_docs+test_obj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:04.564907Z",
     "start_time": "2020-08-08T18:45:04.549569Z"
    }
   },
   "outputs": [],
   "source": [
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use simple unigram word features, handling negation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:05.570230Z",
     "start_time": "2020-08-08T18:45:05.558599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "print(len(unigram_feats))\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply features to obtain a feature-value representation of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:06.494000Z",
     "start_time": "2020-08-08T18:45:06.489841Z"
    }
   },
   "outputs": [],
   "source": [
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train classifier and output evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T18:45:06.980618Z",
     "start_time": "2020-08-08T18:45:06.904317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)\n",
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
